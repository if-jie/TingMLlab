{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduce size and latency of neural network\n",
    "## fine-gained pruning; \n",
    "## channel peuning;\n",
    "## speedup\n",
    "## trade off between pruning approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from collections import OrderedDict, defaultdict\n",
    "from typing import Union, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torchprofile import profile_macs\n",
    "\n",
    "assert torch.cuda.is_available(), \\\n",
    "\"The current runtime does not have CUDA support.\" \\\n",
    "\"Please go to menu bar (Runtime - Change runtime type) and select GPU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    ARCH = [64,128,'M',256,256,'M',512,512,'M',512,512,'M']\n",
    "\n",
    "    def __init__(self)->None:\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        counts = defaultdict(int)\n",
    "\n",
    "        def add(name: str, layer: nn.Module)->None:\n",
    "            layers.append((f\"{name}{counts[name]}\", layer))\n",
    "            counts[name] += 1\n",
    "        in_channels = 3\n",
    "        for x in self.ARCH:\n",
    "            if x != 'M':\n",
    "                #conv bn relu\n",
    "                add(\"conv\", nn.Conv2d(in_channels, x, 3, padding=1, bias=False))\n",
    "                add(\"bn\", nn.BatchNorm2d(x))\n",
    "                add(\"relu\", nn.ReLU(True))\n",
    "                in_channels = x\n",
    "            else:\n",
    "                #maxpool\n",
    "                add(\"pool\", nn.MaxPool2d(2))\n",
    "        \n",
    "        self.backbone = nn.Sequential(OrderedDict(layers))\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor)->torch.Tensor:\n",
    "        #backbone: [N,3,32,32] => [N,512,2,2]\n",
    "        x = self.backbone(x)\n",
    "\n",
    "        #avgpoo: [N,512,2,2] => [N,512]\n",
    "        x = x.mean([2,3])\n",
    "\n",
    "        #classifier: [N,512] => [N,10]\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = VGG().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  criterion: nn.Module,\n",
    "  optimizer: Optimizer,\n",
    "  scheduler: LambdaLR,\n",
    "  callbacks = None\n",
    ") -> None:\n",
    "  model.train()\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc='train', leave=False):\n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Reset the gradients (from the last iteration)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward inference\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward propagation\n",
    "    loss.backward()\n",
    "\n",
    "    # Update optimizer and LR scheduler\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if callbacks is not None:\n",
    "        for callback in callbacks:\n",
    "            callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def evaluate(\n",
    "  model: nn.Module,\n",
    "  dataloader: DataLoader,\n",
    "  verbose=True,\n",
    ") -> float:\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False,\n",
    "                              disable=not verbose):\n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Inference\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Convert logits to class indices\n",
    "    outputs = outputs.argmax(dim=1)\n",
    "\n",
    "    # Update metrics\n",
    "    num_samples += targets.size(0)\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_macs(model, inputs) -> int:\n",
    "    return profile_macs(model, inputs)\n",
    "\n",
    "\n",
    "def get_sparsity(tensor: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    calculate the sparsity of the given tensor\n",
    "        sparsity = #zeros / #elements = 1 - #nonzeros / #elements\n",
    "    \"\"\"\n",
    "    return 1 - float(tensor.count_nonzero()) / tensor.numel()\n",
    "\n",
    "\n",
    "def get_model_sparsity(model: nn.Module) -> float:\n",
    "    \"\"\"\n",
    "    calculate the sparsity of the given model\n",
    "        sparsity = #zeros / #elements = 1 - #nonzeros / #elements\n",
    "    \"\"\"\n",
    "    num_nonzeros, num_elements = 0, 0\n",
    "    for param in model.parameters():\n",
    "        num_nonzeros += param.count_nonzero()\n",
    "        num_elements += param.numel()\n",
    "    return 1 - float(num_nonzeros) / num_elements\n",
    "\n",
    "def get_num_parameters(model: nn.Module, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the total number of parameters of model\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    num_counted_elements = 0\n",
    "    for param in model.parameters():\n",
    "        if count_nonzero_only:\n",
    "            num_counted_elements += param.count_nonzero()\n",
    "        else:\n",
    "            num_counted_elements += param.numel()\n",
    "    return num_counted_elements\n",
    "\n",
    "\n",
    "def get_model_size(model: nn.Module, data_width=32, count_nonzero_only=False) -> int:\n",
    "    \"\"\"\n",
    "    calculate the model size in bits\n",
    "    :param data_width: #bits per element\n",
    "    :param count_nonzero_only: only count nonzero weights\n",
    "    \"\"\"\n",
    "    return get_num_parameters(model, count_nonzero_only) * data_width\n",
    "\n",
    "Byte = 8\n",
    "KiB = 1024 * Byte\n",
    "MiB = 1024 * KiB\n",
    "GiB = 1024 * MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fine_grained_prune(\n",
    "    test_tensor=torch.tensor([[-0.46, -0.40, 0.39, 0.19, 0.37],\n",
    "                              [0.00, 0.40, 0.17, -0.15, 0.16],\n",
    "                              [-0.20, -0.23, 0.36, 0.25, 0.03],\n",
    "                              [0.24, 0.41, 0.07, 0.13, -0.15],\n",
    "                              [0.48, -0.09, -0.36, 0.12, 0.45]]),\n",
    "    test_mask=torch.tensor([[True, True, False, False, False],\n",
    "                            [False, True, False, False, False],\n",
    "                            [False, False, False, False, False],\n",
    "                            [False, True, False, False, False],\n",
    "                            [True, False, False, False, True]]),\n",
    "    target_sparsity=0.75, target_nonzeros=None):\n",
    "    def plot_matrix(tensor, ax, title):\n",
    "        ax.imshow(tensor.cpu().numpy() == 0, vmin=0, vmax=1, cmap='tab20c')\n",
    "        ax.set_title(title)\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_xticklabels([])\n",
    "        for i in range(tensor.shape[1]):\n",
    "            for j in range(tensor.shape[0]):\n",
    "                text = ax.text(j, i, f'{tensor[i, j].item():.2f}',\n",
    "                                ha=\"center\", va=\"center\", color=\"k\")\n",
    "\n",
    "    test_tensor = test_tensor.clone()\n",
    "    fig, axes = plt.subplots(1,2, figsize=(6, 10))\n",
    "    ax_left, ax_right = axes.ravel()\n",
    "    plot_matrix(test_tensor, ax_left, 'dense tensor')\n",
    "\n",
    "    sparsity_before_pruning = get_sparsity(test_tensor)\n",
    "    mask = fine_grained_prune(test_tensor, target_sparsity)\n",
    "    sparsity_after_pruning = get_sparsity(test_tensor)\n",
    "    sparsity_of_mask = get_sparsity(mask)\n",
    "\n",
    "    plot_matrix(test_tensor, ax_right, 'sparse tensor')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print('* Test fine_grained_prune()')\n",
    "    print(f'    target sparsity: {target_sparsity:.2f}')\n",
    "    print(f'        sparsity before pruning: {sparsity_before_pruning:.2f}')\n",
    "    print(f'        sparsity after pruning: {sparsity_after_pruning:.2f}')\n",
    "    print(f'        sparsity of pruning mask: {sparsity_of_mask:.2f}')\n",
    "\n",
    "    if target_nonzeros is None:\n",
    "        if test_mask.equal(mask):\n",
    "            print('* Test passed.')\n",
    "        else:\n",
    "            print('* Test failed.')\n",
    "    else:\n",
    "        if mask.count_nonzero() == target_nonzeros:\n",
    "            print('* Test passed.')\n",
    "        else:\n",
    "            print('* Test failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def download_url(url, root='.', filename=None):\n",
    "    \"\"\"\n",
    "    Download a file from a url and save it to the specified root directory.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL to download the file from.\n",
    "        root (str): Directory to save the downloaded file.\n",
    "        filename (str): Name of the file to save. If None, the filename will be extracted from the URL.\n",
    "    \n",
    "    Returns:\n",
    "        str: Path to the downloaded file.\n",
    "    \"\"\"\n",
    "    # 如果没有提供filename，则从URL中提取\n",
    "    if filename is None:\n",
    "        filename = os.path.basename(url)\n",
    "    \n",
    "    # 确保保存文件的目录存在\n",
    "    os.makedirs(root, exist_ok=True)\n",
    "    \n",
    "    # 构造文件的完整路径\n",
    "    file_path = os.path.join(root, filename)\n",
    "    \n",
    "    # 下载文件\n",
    "    response = requests.get(url, stream=True)\n",
    "    response.raise_for_status()  # 确保请求成功\n",
    "    \n",
    "    with open(file_path, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    \n",
    "    return file_path\n",
    "\n",
    "# 使用download_url函数下载模型\n",
    "checkpoint_url = \"https://hanlab18.mit.edu/files/course/labs/vgg.cifar.pretrained.pth\"\n",
    "checkpoint_path = download_url(checkpoint_url)\n",
    "\n",
    "# 加载模型权重\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'https://hanlab18.mit.edu/files/course/labs/vgg.cifar.pretrained.pth'\n"
     ]
    }
   ],
   "source": [
    "#checkpoint_url = \"https://hanlab18.mit.edu/files/course/labs/vgg.cifar.pretrained.pth\"  \n",
    "#checkpoint = torch.load(download_url(checkpoint_url), map_location=\"cpu\")\n",
    "model = VGG().cuda()\n",
    "print(f\"=> loading checkpoint '{checkpoint_url}'\")\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "recover_model = lambda: model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = {\n",
    "    \"train\": Compose([\n",
    "        RandomCrop(32, padding=4),\n",
    "        RandomHorizontalFlip(),\n",
    "        ToTensor(),\n",
    "    ]),\n",
    "    \"test\": ToTensor(),\n",
    "}\n",
    "dataset = {}\n",
    "for split in [\"train\", \"test\"]:\n",
    "  dataset[split] = CIFAR10(\n",
    "    root=\"./cifar-10-py\",\n",
    "    train=(split == \"train\"),\n",
    "    download=0,  # 设置为True以下载数据集\n",
    "    transform=transforms[split],\n",
    "  )\n",
    "dataLoader = {}\n",
    "\n",
    "for split in ['train', 'test']:\n",
    "    dataLoader[split] = DataLoader(\n",
    "        dataset[split],\n",
    "        batch_size=512,\n",
    "        shuffle=(split == 'train'),\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reflect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
